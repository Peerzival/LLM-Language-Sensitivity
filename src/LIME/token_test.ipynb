{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bigbench.models.huggingface_models as huggingface_models\n",
    "from captum.attr import Lime\n",
    "from captum.attr import visualization as viz\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "def show_text_attr(tokens, attrs):\n",
    "    def rgb(x): return '255,0,0' if x < 0 else '0,255,0'\n",
    "    def alpha(x): return abs(x) ** 0.5\n",
    "    token_marks = [\n",
    "        f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "        for token, attr in zip(tokens, attrs.tolist())\n",
    "    ]\n",
    "\n",
    "    display(HTML('<p>' + ' '.join(token_marks) + '</p>'))\n",
    "\n",
    "# def show_text_attr(tokens, attrs):\n",
    "#     def rgb(x): return 'red' if x < 0 else 'green'\n",
    "#     def alpha(x): return abs(x) ** 0.5\n",
    "#     token_marks = [\n",
    "#         f'\\\\textcolor[rgb]{{{rgb(attr)},{alpha(attr),{alpha(attr)}}{{{token}}}'\n",
    "#         for token, attr in zip(tokens, attrs.tolist())\n",
    "#     ]\n",
    "\n",
    "    latex_output = ' '.join(token_marks)\n",
    "    return latex_output\n",
    "\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "def predict(inputs):\n",
    "    text = [tokenizer.decode(input) for input in inputs]\n",
    "    return torch.tensor([model.cond_log_prob(t, \"He's recovering\") for t in text])\n",
    "\n",
    "input = \"\"\"CHAPTER XXIX \\n\\nFrona had gone at once to her father's side, but he was already recovering. Courbertin was brought forward with a scratched face, sprained wrist, and an insubordinate tongue. To prevent discussion and to save time, Bill Brown claimed the floor. \\n\\n\\\"Mr. Chairman, while we condemn the attempt on the part of Jacob Welse, Frona Welse, and Baron Courbertin to rescue the prisoner and thwart justice, we cannot, under the circumstances, but sympathize with them. There is no need that I should go further into this matter. You all know, and doubtless, under a like situation, would have done the same. And so, in order that we may expeditiously finish the business, I make a motion to disarm the three prisoners and let them go.\\\" \\n\\nThe motion was carried, and the two men searched for weapons. Frona was saved this by giving her word that she was no longer armed. The meeting then resolved itself into a hanging committee, and began to file out of the cabin. \\n\\n\\\"Sorry I had to do it,\\\" the chairman said, half-apologetically, half-defiantly. \\n\\nJacob Welse smiled. \\\"You took your chance,\\\" he answered, \\\"and I can't blame you. I only wish I'd got you, though.\\\" \\n\\nExcited voices arose from across the cabin. \\\"Here, you! Leggo!\\\" \\\"Step on his fingers, Tim!\\\" \\\"Break that grip!\\\" \\\"Ouch! Ow!\\\" \\\"Pry his mouth open!\\\" \\n\\nFrona saw a knot of struggling men about St. Vincent, and ran over. He had thrown himself down on the floor and, tooth and nail, was fighting like a madman. Tim Dugan, a stalwart Celt, had come to close quarters with him, and St. Vincent's teeth were sunk in the man's arm.\n",
    "How is Frona's father doing?\n",
    "\"\"\"\n",
    "\n",
    "model = huggingface_models.BIGBenchHFModel('gpt2-large')\n",
    "\n",
    "# Tokenize the input\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n",
    "input_ids = tokenizer.encode(input, return_tensors='pt')\n",
    "\n",
    "lime = Lime(predict)\n",
    "\n",
    "explanation = lime.attribute(input_ids.squeeze(), target=0, show_progress=True)\n",
    "\n",
    "# Decode the entire sequence of token IDs into a string\n",
    "text = tokenizer.decode(input_ids.squeeze())\n",
    "\n",
    "# Split the string into individual tokens\n",
    "tokens = text.split()\n",
    "\n",
    "# Call show_text_attr with the list of tokens and the attributions\n",
    "show_text_attr(tokens, explanation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
